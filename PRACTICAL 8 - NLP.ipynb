{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6390dd",
   "metadata": {},
   "source": [
    "1.\tWrite a Python program using NLTK to define a context-free grammar (CFG) that can parse simple sentences like \"The cat sat on the mat.\" Use this grammar to generate the parse tree for the sentence.\n",
    "\n",
    "2.\tUsing NLTK, write a function that takes a sentence as input and returns all possible parse trees using a given CFG. Demonstrate this function with the sentence \"I saw the man with the telescope.\"\n",
    "\n",
    "3.\tWrite a Python program using NLTK to create a recursive descent parser for a given CFG. Parse the sentence \"She eats a sandwich.\" and display the parse tree.\n",
    "\n",
    "4.\tUsing NLTK, write a program to extract noun phrases from a sentence using a chunk grammar. Apply it to the sentence \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "5.\tWrite a Python function using NLTK that takes a sentence as input and returns the verb phrases (VP) using a chunk grammar. Demonstrate this function with the sentence \"The cat is sleeping on the mat.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a75d26",
   "metadata": {},
   "source": [
    "1.\tWrite a Python program using NLTK to define a context-free grammar (CFG) that can parse simple sentences like \"The cat sat on the mat.\" Use this grammar to generate the parse tree for the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1daecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Det The) (N cat))\n",
      "  (VP (V sat) (PP (P on) (NP (Det the) (N mat)))))\n",
      "             S                     \n",
      "      _______|_______               \n",
      "     |               VP            \n",
      "     |        _______|___           \n",
      "     |       |           PP        \n",
      "     |       |    _______|___       \n",
      "     NP      |   |           NP    \n",
      "  ___|___    |   |        ___|___   \n",
      "Det      N   V   P      Det      N \n",
      " |       |   |   |       |       |  \n",
      "The     cat sat  on     the     mat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Define a Context-Free Grammar (CFG)\n",
    "cfg_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N\n",
    "    VP -> V PP | V\n",
    "    PP -> P NP\n",
    "    Det -> 'The' | 'the' | 'A' | 'a'\n",
    "    N -> 'cat' | 'dog' | 'mat' | 'boy'\n",
    "    V -> 'sat' | 'sleeps' | 'runs'\n",
    "    P -> 'on' | 'under' | 'beside'\n",
    "\"\"\")\n",
    "\n",
    "# Initialize the parser\n",
    "parser = nltk.ChartParser(cfg_grammar)\n",
    "\n",
    "# Define the sentence to parse\n",
    "sentence = \"The cat sat on the mat\".split()\n",
    "\n",
    "# Generate and display the parse tree\n",
    "for tree in parser.parse(sentence):\n",
    "    print(tree)\n",
    "    tree.pretty_print()  # Opens an NLTK window to visualize the tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ab912",
   "metadata": {},
   "source": [
    "2.\tUsing NLTK, write a function that takes a sentence as input and returns all possible parse trees using a given CFG. Demonstrate this function with the sentence \"I saw the man with the telescope.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed79945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Tree 1:\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Det the) (N man)))\n",
      "    (PP (P with) (NP (Det the) (N telescope)))))\n",
      "     S                                    \n",
      "  ___|___________                          \n",
      " |               VP                       \n",
      " |        _______|________                 \n",
      " |       VP               PP              \n",
      " |    ___|___         ____|___             \n",
      " |   |       NP      |        NP          \n",
      " |   |    ___|___    |     ___|______      \n",
      " NP  V  Det      N   P   Det         N    \n",
      " |   |   |       |   |    |          |     \n",
      " I  saw the     man with the     telescope\n",
      "\n",
      "Parse Tree 2:\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N man) (PP (P with) (NP (Det the) (N telescope))))))\n",
      "     S                                \n",
      "  ___|_______                          \n",
      " |           VP                       \n",
      " |    _______|___                      \n",
      " |   |           NP                   \n",
      " |   |    _______|____                 \n",
      " |   |   |   |        PP              \n",
      " |   |   |   |    ____|___             \n",
      " |   |   |   |   |        NP          \n",
      " |   |   |   |   |     ___|______      \n",
      " NP  V  Det  N   P   Det         N    \n",
      " |   |   |   |   |    |          |     \n",
      " I  saw the man with the     telescope\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Define an ambiguous Context-Free Grammar (CFG)\n",
    "cfg_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    PP -> P NP\n",
    "    Det -> 'the'\n",
    "    N -> 'man' | 'telescope'\n",
    "    V -> 'saw'\n",
    "    P -> 'with'\n",
    "\"\"\")\n",
    "\n",
    "# Function to generate and return all possible parse trees\n",
    "def generate_parse_trees(sentence):\n",
    "    parser = nltk.ChartParser(cfg_grammar)\n",
    "    sentence_tokens = sentence.split()\n",
    "    trees = list(parser.parse(sentence_tokens))  # Generate all trees\n",
    "\n",
    "    if not trees:\n",
    "        print(\"No valid parse trees found.\")\n",
    "        return\n",
    "\n",
    "    # Display all parse trees\n",
    "    for i, tree in enumerate(trees, 1):\n",
    "        print(f\"Parse Tree {i}:\")\n",
    "        print(tree)\n",
    "        tree.pretty_print()  # Opens NLTK tree visualization\n",
    "\n",
    "# Test sentence\n",
    "sentence = \"I saw the man with the telescope\"\n",
    "generate_parse_trees(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc49012",
   "metadata": {},
   "source": [
    "3.\tWrite a Python program using NLTK to create a recursive descent parser for a given CFG. Parse the sentence \"She eats a sandwich.\" and display the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f326c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (Pronoun She)) (VP (V eats) (NP (Det a) (N sandwich))))\n",
      "              S                  \n",
      "    __________|___                \n",
      "   |              VP             \n",
      "   |      ________|___            \n",
      "   NP    |            NP         \n",
      "   |     |         ___|_____      \n",
      "Pronoun  V       Det        N    \n",
      "   |     |        |         |     \n",
      "  She   eats      a      sandwich\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Define the Context-Free Grammar (CFG)\n",
    "cfg_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Pronoun | Det N\n",
    "    VP -> V NP\n",
    "    Det -> 'a' | 'the'\n",
    "    N -> 'sandwich' | 'apple'\n",
    "    Pronoun -> 'She' | 'He'\n",
    "    V -> 'eats' | 'likes'\n",
    "\"\"\")\n",
    "\n",
    "# Function to parse a sentence using Recursive Descent Parser\n",
    "def parse_sentence(sentence):\n",
    "    parser = nltk.RecursiveDescentParser(cfg_grammar)\n",
    "    sentence_tokens = sentence.split()  # Tokenize sentence\n",
    "    trees = list(parser.parse(sentence_tokens))  # Generate parse trees\n",
    "\n",
    "    if not trees:\n",
    "        print(\"No valid parse trees found.\")\n",
    "        return\n",
    "\n",
    "    # Display parse tree(s)\n",
    "    for tree in trees:\n",
    "        print(tree)\n",
    "        tree.pretty_print()  # Opens the NLTK parse tree visualization\n",
    "\n",
    "# Test sentence\n",
    "sentence = \"She eats a sandwich\"\n",
    "parse_sentence(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce7c8f",
   "metadata": {},
   "source": [
    "4.\tUsing NLTK, write a program to extract noun phrases from a sentence using a chunk grammar. Apply it to the sentence \"The quick brown fox jumps over the lazy dog.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0675fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Noun Phrases: ['The quick brown fox', 'the lazy dog']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Ensure necessary resources are downloaded\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "def extract_noun_phrases(sentence):\n",
    "    # Tokenize and POS tag the sentence\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "    # Define chunk grammar for Noun Phrases (NP)\n",
    "    grammar = r\"\"\"\n",
    "        NP: {<DT>?<JJ>*<NN>+}   # Determiner (optional) + Adjectives (0 or more) + Noun(s)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a chunk parser\n",
    "    chunk_parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "    # Apply chunking\n",
    "    chunk_tree = chunk_parser.parse(pos_tags)\n",
    "\n",
    "    # Extract and print noun phrases\n",
    "    noun_phrases = []\n",
    "    for subtree in chunk_tree.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "        noun_phrases.append(\" \".join(word for word, tag in subtree.leaves()))\n",
    "\n",
    "    return noun_phrases\n",
    "\n",
    "# Test sentence\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "noun_phrases = extract_noun_phrases(sentence)\n",
    "\n",
    "# Output results\n",
    "print(\"Extracted Noun Phrases:\", noun_phrases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b426db",
   "metadata": {},
   "source": [
    "5.\tWrite a Python function using NLTK that takes a sentence as input and returns the verb phrases (VP) using a chunk grammar. Demonstrate this function with the sentence \"The cat is sleeping on the mat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dfdfc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Verb Phrases: ['is sleeping']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Ensure necessary resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def extract_verb_phrases(sentence):\n",
    "    # Tokenize and POS tag the sentence\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "    # Define chunk grammar for Verb Phrases (VP)\n",
    "    grammar = r\"\"\"\n",
    "        VP: {<VB.*><RB.*>?<VBG|VBN>?<PP>?}\n",
    "    \"\"\"\n",
    "    # Explanation: VB.* (any verb), optional adverb (RB), optional gerund/past participle (VBG/VBN), optional prepositional phrase (PP)\n",
    "\n",
    "    # Create a chunk parser\n",
    "    chunk_parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "    # Apply chunking\n",
    "    chunk_tree = chunk_parser.parse(pos_tags)\n",
    "\n",
    "    # Extract and return verb phrases\n",
    "    verb_phrases = []\n",
    "    for subtree in chunk_tree.subtrees(filter=lambda t: t.label() == 'VP'):\n",
    "        verb_phrases.append(\" \".join(word for word, tag in subtree.leaves()))\n",
    "\n",
    "    return verb_phrases\n",
    "\n",
    "# Test sentence\n",
    "sentence = \"The cat is sleeping on the mat.\"\n",
    "verb_phrases = extract_verb_phrases(sentence)\n",
    "\n",
    "# Output results\n",
    "print(\"Extracted Verb Phrases:\", verb_phrases)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

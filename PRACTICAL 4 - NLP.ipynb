{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5143b12",
   "metadata": {},
   "source": [
    "1.\tExplain the difference between assigning a list to a new variable using direct assignment (=) and using the copy() method. Provide code examples to illustrate the difference.\n",
    "\n",
    "2.\tWrite a function extract_nouns(text) that takes a text string as input and returns a list of all nouns in the text. Use NLTK's part-of-speech tagging for this task.\n",
    "\n",
    "3.\tDemonstrate how to use list comprehension to create a list of the lengths of each word in a given sentence.\n",
    "\n",
    "4.\tWrite a function word_frequency(text) that takes a text string and returns a dictionary with words as keys and their frequencies as values.\n",
    "\n",
    "5.\tExplain the concept of variable scope in Python with an example demonstrating the difference between local and global variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba84826",
   "metadata": {},
   "source": [
    "1.\tExplain the difference between assigning a list to a new variable using direct assignment (=) and using the copy() method. Provide code examples to illustrate the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3279228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list1: [1, 2, 3, 4]\n",
      "list2: [1, 2, 3, 4]\n",
      "list3: [1, 2, 3]\n",
      "list4: [1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# direct assignment affects the original list, and how copy keeps it separate.\n",
    "\n",
    "# Direct Assignment\n",
    "list1 = [1, 2, 3]\n",
    "list2 = list1  # list2 points to the same list as list1\n",
    "list2.append(4)\n",
    "print(f\"list1: {list1}\")  # Output: [1, 2, 3, 4]\n",
    "print(f\"list2: {list2}\")  # Output: [1, 2, 3, 4]\n",
    "\n",
    "# Using the copy() method\n",
    "list3 = [1, 2, 3]\n",
    "list4 = list3.copy()  # list4 is a new independent copy of list3\n",
    "list4.append(4)\n",
    "print(f\"list3: {list3}\")  # Output: [1, 2, 3]\n",
    "print(f\"list4: {list4}\")  # Output: [1, 2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5240f1b",
   "metadata": {},
   "source": [
    "2.\tWrite a function extract_nouns(text) that takes a text string as input and returns a list of all nouns in the text. Use NLTK's part-of-speech tagging for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c768d58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown', 'fox', 'dog']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# Download the required resource for English\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng') # Download the resource for english language\n",
    "\n",
    "def extract_nouns(text):\n",
    "    # Tokenize the text and tag parts of speech\n",
    "    words = word_tokenize(text)\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    # Extract nouns (both singular and plural)\n",
    "    nouns = [word for word, tag in tagged_words if tag in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
    "    return nouns\n",
    "\n",
    "# Example usage\n",
    "text = \"The quick brown fox jumped over the lazy dog.\"\n",
    "print(extract_nouns(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c2029",
   "metadata": {},
   "source": [
    "3.\tDemonstrate how to use list comprehension to create a list of the lengths of each word in a given sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe86c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 5, 3, 6, 4, 3, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumped over the lazy dog.\"\n",
    "word_lengths = [len(word) for word in sentence.split()]\n",
    "print(word_lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c210790f",
   "metadata": {},
   "source": [
    "4.\tWrite a function word_frequency(text) that takes a text string and returns a dictionary with words as keys and their frequencies as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71462e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 2, 'is': 2, 'a': 2, 'test': 2, '.': 2, 'only': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lalit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def word_frequency(text):\n",
    "    words = word_tokenize(text)\n",
    "    frequency_dict = {}\n",
    "    for word in words:\n",
    "        word = word.lower()  # Normalize to lowercase\n",
    "        frequency_dict[word] = frequency_dict.get(word, 0) + 1\n",
    "    return frequency_dict\n",
    "\n",
    "# Example usage\n",
    "text = \"This is a test. This is only a test.\"\n",
    "print(word_frequency(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e8353c",
   "metadata": {},
   "source": [
    "5.\tExplain the concept of variable scope in Python with an example demonstrating the difference between local and global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4bc4856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local variable y: 20\n",
      "Global variable x: 10\n",
      "Global variable x outside function: 10\n"
     ]
    }
   ],
   "source": [
    "#  Explanation:\n",
    "# A global variable is defined outside any function and is accessible inside functions (if not overridden).\n",
    "# A local variable is defined inside a function and only accessible within that function.\n",
    "\n",
    "x = 10  # Global variable\n",
    "\n",
    "def example_function():\n",
    "    y = 20  # Local variable\n",
    "    print(f\"Local variable y: {y}\")\n",
    "    print(f\"Global variable x: {x}\")\n",
    "\n",
    "example_function()\n",
    "\n",
    "\n",
    "print(f\"Global variable x outside function: {x}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
